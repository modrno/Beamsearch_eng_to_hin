# -*- coding: utf-8 -*-
"""BeamSearch_eng_to_hin(task4).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I2lSi2dD8fSFevQf1itx5r0cOcjy_gqZ

**Beam Search Decoding**
"""

!pip install transformers torch

import torch
from transformers import MarianMTModel, MarianTokenizer

model_name_hi = 'Helsinki-NLP/opus-mt-en-hi'
tokenizer_hi = MarianTokenizer.from_pretrained(model_name_hi)
model_hi = MarianMTModel.from_pretrained(model_name_hi)

def beam_search_decode(input_text, beam_size=5, max_length=50):

    inputs = tokenizer_hi(input_text, return_tensors="pt", padding=True)


    with torch.no_grad():
        outputs = model_hi.generate(
            **inputs,
            num_beams=beam_size,
            max_length=max_length,
            early_stopping=True,
            no_repeat_ngram_size=2,
        )


    decoded_output = tokenizer_hi.decode(outputs[0], skip_special_tokens=True)
    return decoded_output

if __name__ == "__main__":
    input_text = "Hello, what you doing?"
    translated_text = beam_search_decode(input_text, beam_size=5)
    print(f"Translated Text: {translated_text}")

